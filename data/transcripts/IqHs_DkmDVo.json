[{"text": "Dear Fellow Scholars, this is Two Minute Papers\nwith K\u00e1roly Zsolnai-Feh\u00e9r.", "start": 0.359, "duration": 3.12}, {"text": "A few years ago, the Generative Adversarial\nNetwork architecture appeared that contains", "start": 3.479, "duration": 6.301}, {"text": "two neural networks that try to outcompete\neach other.", "start": 9.78, "duration": 4.109}, {"text": "It has been used extensively for image generation,\nand has become a research subfield of its", "start": 13.889, "duration": 5.201}, {"text": "own.", "start": 19.09, "duration": 1.0}, {"text": "For instance, they can generate faces of people\nthat don\u2019t exist and much, much more.", "start": 20.09, "duration": 5.67}, {"text": "This is great, we should be grateful to live\nin a time when breakthroughs like this happen", "start": 25.76, "duration": 4.33}, {"text": "in AI research.", "start": 30.09, "duration": 1.44}, {"text": "However, we should also note that artists\nusually have a vision of the work that they", "start": 31.53, "duration": 4.451}, {"text": "would like to create, and instead of just\ngetting a deluge of new images, most of them", "start": 35.981, "duration": 5.119}, {"text": "would prefer to have some sort of artistic\ncontrol over the results.", "start": 41.1, "duration": 4.74}, {"text": "This work offers something that they call\nsemantic paint brushes.", "start": 45.84, "duration": 4.33}, {"text": "This means that we can paint not in terms\nof colors, but in terms of concepts.", "start": 50.17, "duration": 5.14}, {"text": "Now this may sound a little nebulous, so if\nyou look here, you see that as a result, we", "start": 55.31, "duration": 5.08}, {"text": "can grow trees, change buildings, and do all\nkinds of shenanigans without requiring us", "start": 60.39, "duration": 5.82}, {"text": "to be able to draw the results by hand.", "start": 66.21, "duration": 3.45}, {"text": "Look at those marvelous results!", "start": 69.66, "duration": 2.35}, {"text": "It works by compressing down these images\ninto a latent space.", "start": 72.01, "duration": 4.0}, {"text": "This is a representation that is quite sparse\nand captures the essence of these images.", "start": 76.01, "duration": 5.96}, {"text": "One of the key ideas is that this can then\nbe reconstructed by a generator neural network", "start": 81.97, "duration": 5.13}, {"text": "to get a similar image back, however, the\ntwist is that while we are in the latent domain,", "start": 87.1, "duration": 6.03}, {"text": "we can apply these intuitive edits to this\nimage, so when the generator step takes place,", "start": 93.13, "duration": 5.529}, {"text": "it will carry through our changes.", "start": 98.659, "duration": 2.231}, {"text": "If you look at the paper, you will see that\njust using one generator network doesn\u2019t", "start": 100.89, "duration": 4.6}, {"text": "yield these great results, therefore this\ngenerator needs to be specific to the image", "start": 105.49, "duration": 5.519}, {"text": "we are currently editing.", "start": 111.009, "duration": 1.951}, {"text": "The included user study shows that the new\nmethod is preferred over the previous techniques.", "start": 112.96, "duration": 5.36}, {"text": "Now, like all of these methods, this is not\nwithout limitations.", "start": 118.32, "duration": 4.85}, {"text": "Here you see that despite trying to remove\nthe chairs from the scene, amusingly, we get", "start": 123.17, "duration": 4.71}, {"text": "them right back.", "start": 127.88, "duration": 1.01}, {"text": "That\u2019s a bunch of chairs free of charge,\nin fact, I am not even sure how many chairs", "start": 128.89, "duration": 5.74}, {"text": "we got here.", "start": 134.63, "duration": 1.03}, {"text": "If you figured that out, make sure to leave\na comment about it, but all in all, that\u2019s", "start": 135.66, "duration": 4.28}, {"text": "not what we asked for, and solving this remains\na challenge for the entire family of these", "start": 139.94, "duration": 5.409}, {"text": "algorithms.", "start": 145.349, "duration": 1.0}, {"text": "And, good news, in fact, when talking about\na paper, probably the best kind of news is", "start": 146.349, "duration": 6.041}, {"text": "that you can try it online through a web demo\nright now.", "start": 152.39, "duration": 3.89}, {"text": "Make sure to try it out and post your results\nhere if you find anything interesting.", "start": 156.28, "duration": 4.29}, {"text": "The authors themselves may also learn something\nnew from us about interesting new failure", "start": 160.57, "duration": 4.94}, {"text": "cases.", "start": 165.51, "duration": 1.0}, {"text": "It has happened before in this series.", "start": 166.51, "duration": 2.77}, {"text": "This episode has been supported by Weights\n& Biases.", "start": 169.28, "duration": 3.33}, {"text": "Weights & Biases provides tools to track your\nexperiments in your deep learning projects.", "start": 172.61, "duration": 4.55}, {"text": "It is like a shared logbook for your team,\nand with this, you can compare your own experiment", "start": 177.16, "duration": 5.31}, {"text": "results, put them next to what your colleagues\ndid and you can discuss your successes and", "start": 182.47, "duration": 4.64}, {"text": "failures much easier.", "start": 187.11, "duration": 2.03}, {"text": "It takes less than 5 minutes to set up and\nis being used by OpenAI, Toyota Research,", "start": 189.14, "duration": 5.67}, {"text": "Stanford and Berkeley.", "start": 194.81, "duration": 1.93}, {"text": "It was also used in this OpenAI project that\nyou see here, which we covered earlier in", "start": 196.74, "duration": 4.69}, {"text": "the series.", "start": 201.43, "duration": 1.0}, {"text": "They reported that experiment tracking was\ncrucial in this project and that this tool", "start": 202.43, "duration": 4.741}, {"text": "saved them quite a bit of time and money.", "start": 207.171, "duration": 3.189}, {"text": "If only I had an access to such a tool during\nour last research project where I had to compare", "start": 210.36, "duration": 5.25}, {"text": "the performance of neural networks for months\nand months.", "start": 215.61, "duration": 3.36}, {"text": "Well, it turns out, I will be able to get\naccess to these tools, because, get this,", "start": 218.97, "duration": 5.48}, {"text": "it\u2019s free and will always be free for academics\nand open source projects.", "start": 224.45, "duration": 5.14}, {"text": "Make sure to visit them through wandb.com\nor just click the link in the video description", "start": 229.59, "duration": 9.69}, {"text": "and sign up for a free demo today.", "start": 239.28, "duration": 2.289}, {"text": "Our thanks to Weights & Biases for helping\nus make better videos for you.", "start": 241.569, "duration": 4.03}, {"text": "Thanks for watching and for your generous\nsupport, and I'll see you next time!", "start": 245.599, "duration": 2.321}]