[{"text": "Here we tackle backpropagation,", "start": 4.35, "duration": 2.06}, {"text": "the core algorithm behind how neural networks learn.", "start": 6.41, "duration": 2.99}, {"text": "After a quick recap for where we are,", "start": 9.4, "duration": 1.81}, {"text": "the first thing I'll do is an intuitive walkthrough for what the algorithm is actually doing", "start": 11.21, "duration": 4.26}, {"text": "without any reference to the formulas,", "start": 15.47, "duration": 1.8}, {"text": "Then for those of you who do want to dive into the math,", "start": 17.64, "duration": 2.67}, {"text": "the next video goes into the calculus underlying all this.", "start": 20.31, "duration": 2.83}, {"text": "If you watched the last two videos", "start": 23.94, "duration": 1.61}, {"text": "or if you're just jumping in with the appropriate background,", "start": 25.55, "duration": 2.37}, {"text": "you know what a neural network is and how it feeds forward information.", "start": 27.92, "duration": 3.37}, {"text": "Here we're doing the classic example of recognizing handwritten digits,", "start": 31.66, "duration": 3.44}, {"text": "whose pixel values get fed into the first layer of the network with 784 neurons.", "start": 35.1, "duration": 4.83}, {"text": "And I've been showing a network with two hidden layers having just 16 neurons each,", "start": 39.93, "duration": 4.07}, {"text": "and an output layer of 10 neurons, indicating which digit the network is choosing as its answer.", "start": 44.0, "duration": 5.25}, {"text": "I'm also expecting you to understand gradient descent as described in the last video,", "start": 50.02, "duration": 4.32}, {"text": "and how what we mean by learning is that", "start": 54.34, "duration": 2.55}, {"text": "we want to find which weights and biases minimize a certain cost function.", "start": 56.89, "duration": 4.56}, {"text": "As a quick reminder, for the cost of a single training example,", "start": 62.01, "duration": 3.46}, {"text": "what you do is take the output that the network gives,", "start": 65.47, "duration": 2.93}, {"text": "along with the output that you wanted it to give,", "start": 68.4, "duration": 2.45}, {"text": "and you just add up the squares of the differences between each component.", "start": 71.2, "duration": 3.62}, {"text": "Doing this for all of your tens of thousands of training examples, and averaging the results,", "start": 75.37, "duration": 4.65}, {"text": "this gives you the total cost of the network.", "start": 80.02, "duration": 2.39}, {"text": "And as if that's not enough to think about, as described in the last video,", "start": 82.91, "duration": 3.1}, {"text": "the thing that we're looking for is the negative gradient of this cost function,", "start": 86.01, "duration": 4.86}, {"text": "which tells you how you need to change all of the weights and biases, all of these connections,", "start": 90.87, "duration": 4.85}, {"text": "so as to most efficiently decrease the cost.", "start": 95.72, "duration": 2.55}, {"text": "Backpropagation, the topic of this video,", "start": 102.95, "duration": 2.26}, {"text": "is an algorithm for computing that crazy complicated gradient.", "start": 105.21, "duration": 3.59}, {"text": "And the one idea from the last video that I really want you to hold firmly in your mind right now", "start": 109.49, "duration": 4.52}, {"text": "is that because thinking of the gradient vector as a direction in 13000 dimensions is,", "start": 114.01, "duration": 4.9}, {"text": "to put it lightly, beyond the scope of our imaginations,", "start": 118.91, "duration": 3.18}, {"text": "there's another way you can think about it:", "start": 122.09, "duration": 1.42}, {"text": "The magnitude of each component here is telling you", "start": 124.58, "duration": 3.13}, {"text": "how sensitive the cost function is to each weight and bias.", "start": 127.71, "duration": 3.43}, {"text": "For example, let's say you go through the process I'm about to describe,", "start": 131.81, "duration": 2.77}, {"text": "and you compute the negative gradient,", "start": 134.58, "duration": 1.79}, {"text": "and the component associated with the weight on this edge here comes out to be 3.2,", "start": 136.37, "duration": 5.1}, {"text": "while the component associated with this edge here comes out as 0.1.", "start": 141.87, "duration": 4.5}, {"text": "The way you would interpret that is that", "start": 146.91, "duration": 1.51}, {"text": "the cost of the function is 32 times more sensitive to changes in that first weight.", "start": 148.42, "duration": 4.66}, {"text": "So if you were to wiggle that value just a little bit,", "start": 153.64, "duration": 2.29}, {"text": "it's gonna cause some change to the cost,", "start": 155.93, "duration": 2.26}, {"text": "and that change is 32 times greater than what the same wiggle to that second weight would give.", "start": 158.19, "duration": 5.01}, {"text": "Personally, when I was first learning about backpropagation,", "start": 168.52, "duration": 2.92}, {"text": "I think the most confusing aspect was just the notation and the index chasing of it all.", "start": 171.44, "duration": 4.3}, {"text": "But once you unwrap what each part of this algorithm is really doing,", "start": 176.18, "duration": 3.27}, {"text": "each individual effect that it's having is actually pretty intuitive.", "start": 179.45, "duration": 3.42}, {"text": "It's just that there's a lot of little adjustments getting layered on top of each other.", "start": 183.18, "duration": 3.56}, {"text": "So I'm gonna start things off here with a complete disregard for the notation,", "start": 187.66, "duration": 3.63}, {"text": "and just step through those effects that", "start": 191.29, "duration": 2.08}, {"text": "each training example is having on the weights and biases.", "start": 193.37, "duration": 2.98}, {"text": "Because the cost function involves", "start": 197.09, "duration": 1.5}, {"text": "averaging a certain cost per example over all the tens of thousands of training examples,", "start": 198.59, "duration": 5.05}, {"text": "the way that we adjust the weights and biases for a single gradient descent step", "start": 203.97, "duration": 4.67}, {"text": "also depends on every single example,", "start": 208.64, "duration": 2.5}, {"text": "or rather in principle it should,", "start": 211.68, "duration": 1.52}, {"text": "but for computational efficiency we're going to do a little trick later", "start": 213.2, "duration": 2.73}, {"text": "to keep you from needing to hit every single example for every single step.", "start": 215.93, "duration": 3.44}, {"text": "Another case right now,", "start": 219.79, "duration": 1.54}, {"text": "all we're gonna do is focus our attention on one single example: this image of a 2.", "start": 221.33, "duration": 4.83}, {"text": "What effect should this one training example have on how the weights and biases get adjusted?", "start": 226.67, "duration": 4.98}, {"text": "Let's say we're at a point where the network is not well trained yet,", "start": 232.68, "duration": 2.56}, {"text": "so the activations in the output are gonna look pretty random,", "start": 235.24, "duration": 2.73}, {"text": "maybe something like 0.5, 0.8, 0.2, on and on.", "start": 237.97, "duration": 4.07}, {"text": "Now we can't directly change those activations, we only have influence on the weights and biases,", "start": 242.64, "duration": 4.81}, {"text": "but it is helpful to keep track of which adjustments we wish should take place to that output layer,", "start": 247.79, "duration": 4.88}, {"text": "and since we want it to classify the image as a 2,", "start": 253.27, "duration": 2.44}, {"text": "we want that third value to get nudged up, while all of the others get nudged down.", "start": 256.04, "duration": 5.32}, {"text": "Moreover, the sizes of these nudges should be proportional to", "start": 262.04, "duration": 3.98}, {"text": "how far away each current value is from its target value.", "start": 266.02, "duration": 3.61}, {"text": "For example, the increase to that number 2 neurons activation is,", "start": 270.22, "duration": 4.13}, {"text": "in a sense, more important than the decrease to the number 8 neuron,", "start": 274.35, "duration": 4.14}, {"text": "which is already pretty close to where it should be.", "start": 278.49, "duration": 2.14}, {"text": "So zooming in further, let's focus just on this one neuron,", "start": 281.99, "duration": 3.26}, {"text": "the one whose activation we wish to increase.", "start": 285.25, "duration": 2.28}, {"text": "Remember, that activation is defined as", "start": 288.16, "duration": 2.39}, {"text": "a certain weighted sum of all of the activations in the previous layer, plus a bias,", "start": 290.55, "duration": 5.88}, {"text": "which has all been plugged into something like the sigmoid squishification function or a ReLU,", "start": 296.43, "duration": 4.86}, {"text": "So there are three different avenues that can team up together to help increase that activation:", "start": 301.81, "duration": 5.55}, {"text": "you can increase the bias, you can increase the weights,", "start": 307.68, "duration": 3.29}, {"text": "and you can change the activations from the previous layer.", "start": 310.97, "duration": 3.06}, {"text": "Focusing just on how the weights should be adjusted,", "start": 314.95, "duration": 2.82}, {"text": "notice how the weights actually have differing levels of influence:", "start": 317.77, "duration": 3.64}, {"text": "the connections with the brightest neurons from the preceding layer have the biggest effect,", "start": 321.41, "duration": 4.34}, {"text": "since those weights are multiplied by larger activation values.", "start": 325.75, "duration": 3.49}, {"text": "So if you were to increase one of those weights,", "start": 331.33, "duration": 2.15}, {"text": "it actually has a stronger influence on the ultimate cost function", "start": 333.48, "duration": 3.89}, {"text": "than increasing the weights of connections with dimmer neurons,", "start": 337.37, "duration": 3.45}, {"text": "at least as far as this one training example is concerned.", "start": 340.82, "duration": 2.83}, {"text": "Remember when we talked about gradient descent,", "start": 344.38, "duration": 2.51}, {"text": "we don't just care about whether each component should get nudged up or down,", "start": 346.89, "duration": 3.73}, {"text": "we care about which ones give you the most bang for your buck.", "start": 350.62, "duration": 2.75}, {"text": "This, by the way, is at least somewhat reminiscent of a theory in neuroscience", "start": 355.27, "duration": 4.04}, {"text": "for how biological networks of neurons learn", "start": 359.31, "duration": 2.56}, {"text": "Hebbian theory - often summed up in the phrase \u201cneurons that fire together wire together\u201d.", "start": 361.87, "duration": 4.95}, {"text": "Here, the biggest increases to weights, the biggest strengthening of connections,", "start": 367.26, "duration": 4.94}, {"text": "happens between neurons which are the most active,", "start": 372.2, "duration": 2.64}, {"text": "and the ones which we wish to become more active.", "start": 374.84, "duration": 2.75}, {"text": "In a sense, the neurons that are firing while seeing a 2,", "start": 378.02, "duration": 3.04}, {"text": "get more strongly linked to those firing when thinking about a 2.", "start": 381.06, "duration": 3.62}, {"text": "To be clear, I really am not in a position to make statements one way or another", "start": 385.42, "duration": 3.36}, {"text": "about whether artificial networks of neurons behave anything like biological brains,", "start": 388.78, "duration": 4.3}, {"text": "and this fires-together-wire-together idea comes with a couple meaningful asterisks.", "start": 393.08, "duration": 4.17}, {"text": "But taken as a very loose analogy, I do find it interesting to note.", "start": 397.25, "duration": 4.01}, {"text": "Anyway, the third way that we can help increase this neuron's activation", "start": 401.89, "duration": 4.13}, {"text": "is by changing all the activations in the previous layer,", "start": 406.02, "duration": 3.04}, {"text": "namely, if everything connected to that digit 2 neuron with a positive weight got brighter,", "start": 409.56, "duration": 5.41}, {"text": "and if everything connected with a negative weight got dimmer,", "start": 414.97, "duration": 2.99}, {"text": "then that digit 2 neuron would become more active.", "start": 418.34, "duration": 2.55}, {"text": "And similar to the weight changes, you're going to get the most bang for your buck", "start": 422.45, "duration": 3.68}, {"text": "by seeking changes that are proportional to the size of the corresponding weights.", "start": 426.13, "duration": 4.42}, {"text": "Now of course, we cannot directly influence those activations,", "start": 432.12, "duration": 3.24}, {"text": "we only have control over the weights and biases.", "start": 435.36, "duration": 2.42}, {"text": "But just as with the last layer, it's helpful to just keep a note of what those desired changes are.", "start": 438.22, "duration": 5.39}, {"text": "But keep in mind, zooming out one step here, this is only what that digit 2 output neuron wants.", "start": 444.45, "duration": 5.27}, {"text": "Remember, we also want all of the other neurons in the last layer to become less active,", "start": 449.72, "duration": 5.12}, {"text": "and each of those other output neurons", "start": 454.84, "duration": 1.66}, {"text": "has its own thoughts about what should happen to that second-to-last layer.", "start": 456.5, "duration": 3.34}, {"text": "So, the desire of this digit 2 neuron", "start": 463.11, "duration": 3.03}, {"text": "is added together with the desires of all the other output neurons", "start": 466.14, "duration": 4.38}, {"text": "for what should happen to this second-to-last layer.", "start": 470.52, "duration": 2.72}, {"text": "Again, in proportion to the corresponding weights,", "start": 473.58, "duration": 2.82}, {"text": "and in proportion to how much each of those neurons needs to change.", "start": 476.4, "duration": 4.51}, {"text": "This right here is where the idea of propagating backwards comes in.", "start": 481.48, "duration": 4.03}, {"text": "By adding together all these desired effects,", "start": 485.96, "duration": 2.77}, {"text": "you basically get a list of nudges that you want to happen to the second-to-last layer.", "start": 488.73, "duration": 4.83}, {"text": "And once you have those,", "start": 494.18, "duration": 1.21}, {"text": "you can recursively apply the same process", "start": 495.39, "duration": 2.46}, {"text": "to the relevant weights and biases that determine those values,", "start": 497.85, "duration": 3.33}, {"text": "repeating the same process I just walked through and moving backwards through the network.", "start": 501.18, "duration": 3.96}, {"text": "And zooming out a bit further,", "start": 509.03, "duration": 1.34}, {"text": "remember that this is all just", "start": 510.37, "duration": 1.55}, {"text": "how a single training example wishes to nudge each one of those weights and biases.", "start": 511.92, "duration": 5.48}, {"text": "If we only listen to what that 2 wanted,", "start": 517.4, "duration": 2.3}, {"text": "the network would ultimately be incentivized just to classify all images as a 2.", "start": 519.7, "duration": 3.7}, {"text": "So what you do is you go through this same backprop routine for every other training example,", "start": 524.03, "duration": 5.39}, {"text": "recording how each of them would like to change the weights and the biases,", "start": 529.42, "duration": 3.78}, {"text": "and you averaged together those desired changes.", "start": 533.65, "duration": 2.57}, {"text": "This collection here of the averaged nudges to each weight and bias is,", "start": 542.05, "duration": 4.89}, {"text": "loosely speaking, the negative gradient of the cost function referenced in the last video,", "start": 546.94, "duration": 4.97}, {"text": "or at least something proportional to it.", "start": 551.91, "duration": 1.83}, {"text": "I say \u201cloosely speaking\u201d, only because I have yet to get quantitatively precise about those nudges.", "start": 554.36, "duration": 5.21}, {"text": "But if you understood every change that I just referenced,", "start": 559.57, "duration": 2.62}, {"text": "why some are proportionally bigger than others,", "start": 562.19, "duration": 2.58}, {"text": "and how they all need to be added together,", "start": 564.77, "duration": 2.39}, {"text": "you understand the mechanics for what backpropagation is actually doing.", "start": 567.16, "duration": 4.01}, {"text": "By the way, in practice it takes computers an extremely long time", "start": 574.05, "duration": 3.35}, {"text": "to add up the influence of every single training example, every single gradient descent step.", "start": 577.4, "duration": 5.09}, {"text": "So here's what's commonly done instead:", "start": 583.01, "duration": 1.95}, {"text": "You randomly shuffle your training data, and then divide it into a whole bunch of mini-batches,", "start": 585.44, "duration": 4.84}, {"text": "let's say, each one having 100 training examples.", "start": 590.28, "duration": 2.4}, {"text": "Then you compute a step according to the mini-batch.", "start": 593.24, "duration": 3.19}, {"text": "It's not going to be the actual gradient of the cost function,", "start": 596.85, "duration": 2.54}, {"text": "which depends on all of the training data, not this tiny subset.", "start": 599.39, "duration": 3.24}, {"text": "So it's not the most efficient step downhill.", "start": 603.1, "duration": 2.54}, {"text": "But each mini batch does give you a pretty good approximation,", "start": 606.08, "duration": 2.89}, {"text": "and more importantly, it gives you a significant computational speed up.", "start": 608.97, "duration": 3.28}, {"text": "If you were to plot the trajectory of your network under the relevant cost surface,", "start": 612.82, "duration": 3.99}, {"text": "it would be a little more like a drunk man stumbling aimlessly down a hill, but taking quick steps;", "start": 616.81, "duration": 5.22}, {"text": "rather than a carefully calculating man determining the exact downhill direction of each step", "start": 622.03, "duration": 5.15}, {"text": "before taking a very slow and careful step in that direction.", "start": 627.18, "duration": 3.17}, {"text": "This technique is referred to as \u201cstochastic gradient descent\u201d.", "start": 631.46, "duration": 3.48}, {"text": "There's kind of a lot going on here, so let's just sum it up for ourselves, shall we?", "start": 636.0, "duration": 3.8}, {"text": "Backpropagation is the algorithm", "start": 640.24, "duration": 2.03}, {"text": "for determining how a single training example would like to nudge the weights and biases,", "start": 642.27, "duration": 5.1}, {"text": "not just in terms of whether they should go up or down,", "start": 647.37, "duration": 2.56}, {"text": "but in terms of what relative proportions to those changes cause the most rapid decrease to the cost.", "start": 649.93, "duration": 5.77}, {"text": "A true gradient descent step", "start": 656.24, "duration": 2.03}, {"text": "would involve doing this for all your tens and thousands of training examples", "start": 658.27, "duration": 3.55}, {"text": "and averaging the desired changes that you get.", "start": 661.82, "duration": 2.44}, {"text": "But that's computationally slow.", "start": 664.83, "duration": 1.51}, {"text": "So instead you randomly subdivide the data into these mini-batches", "start": 666.69, "duration": 3.79}, {"text": "and compute each step with respect to a mini-batch.", "start": 670.48, "duration": 2.98}, {"text": "Repeatedly going through all of the mini batches and making these adjustments,", "start": 673.9, "duration": 3.79}, {"text": "you will converge towards a local minimum of the cost function,", "start": 677.69, "duration": 3.36}, {"text": "which is to say, your network is going to end up doing a really good job on the training examples.", "start": 681.43, "duration": 4.31}, {"text": "So with all of that said, every line of code that would go into implementing backprop", "start": 687.45, "duration": 4.84}, {"text": "actually corresponds with something that you have now seen, at least in informal terms.", "start": 692.29, "duration": 4.68}, {"text": "But sometimes knowing what the math does is only half the battle,", "start": 697.57, "duration": 3.39}, {"text": "and just representing the damn thing is where it gets all muddled and confusing.", "start": 700.96, "duration": 3.5}, {"text": "So for those of you who do want to go deeper,", "start": 704.93, "duration": 2.69}, {"text": "the next video goes through the same ideas that were just presented here", "start": 707.62, "duration": 3.05}, {"text": "but in terms of the underlying calculus,", "start": 710.67, "duration": 2.08}, {"text": "which should hopefully make it a little more familiar as you see the topic in other resources.", "start": 712.75, "duration": 4.01}, {"text": "Before that, one thing worth emphasizing is that", "start": 717.21, "duration": 2.23}, {"text": "for this algorithm to work, and this goes for all sorts of machine learning beyond just neural networks,", "start": 719.44, "duration": 4.88}, {"text": "you need a lot of training data.", "start": 724.32, "duration": 1.8}, {"text": "In our case, one thing that makes handwritten digits such a nice example", "start": 726.43, "duration": 3.43}, {"text": "is that there exists the MNIST database", "start": 729.86, "duration": 2.25}, {"text": "with so many examples that have been labeled by humans.", "start": 732.11, "duration": 3.18}, {"text": "So a common challenge that those of you working in machine learning will be familiar with", "start": 735.29, "duration": 3.71}, {"text": "is just getting the labeled training data that you actually need,", "start": 739.0, "duration": 2.93}, {"text": "whether that's having people label tens of thousands of images", "start": 742.24, "duration": 2.84}, {"text": "or whatever other data type you might be dealing with.", "start": 745.08, "duration": 2.47}, {"text": "And this actually transitions really nicely to today's extremely relevant sponsor - CrowdFlower,", "start": 747.87, "duration": 5.29}, {"text": "which is a software platform", "start": 753.16, "duration": 1.18}, {"text": "where data scientists and machine learning teams can create training data.", "start": 754.34, "duration": 3.75}, {"text": "They allow you to upload text or audio or image data,", "start": 758.6, "duration": 3.18}, {"text": "and have it annotated by real people.", "start": 761.78, "duration": 2.1}, {"text": "You may have heard of the human-in-the-loop approach before,", "start": 764.19, "duration": 2.75}, {"text": "and this is essentially what we're talking about here:", "start": 766.94, "duration": 2.39}, {"text": "\u201cleveraging human intelligence to train machine intelligence\u201d.", "start": 769.33, "duration": 3.63}, {"text": "They employ a whole bunch of pretty smart quality control mechanisms", "start": 773.48, "duration": 2.9}, {"text": "to keep the data clean and accurate,", "start": 776.38, "duration": 1.79}, {"text": "and they've helped to train test and tune thousands of data and AI projects.", "start": 778.17, "duration": 4.43}, {"text": "And what's most fun, there's actually a free t-shirt in this for you guys.", "start": 782.6, "duration": 3.76}, {"text": "If you go to 3b1b.co/crowdflower,", "start": 786.36, "duration": 4.21}, {"text": "or follow the link on screen and in the description,", "start": 790.57, "duration": 2.77}, {"text": "you can create a free account and run a project,", "start": 793.34, "duration": 2.77}, {"text": "and they'll send you a free shirt once you've done the job.", "start": 796.11, "duration": 2.43}, {"text": "And the shirt it's actually pretty cool, I quite like it.", "start": 799.0, "duration": 2.07}, {"text": "So thanks to CrowdFlower for supporting this video,", "start": 801.49, "duration": 2.23}, {"text": "and thank you also to everyone on Patreon helping support these videos.", "start": 803.72, "duration": 3.33}]