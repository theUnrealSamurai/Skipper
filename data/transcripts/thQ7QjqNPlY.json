[{"text": "Dear Fellow Scholars, this is Two Minute Papers\nwith K\u00e1roly Zsolnai-Feh\u00e9r.", "start": 0.299, "duration": 4.211}, {"text": "This work presents a learning-based method\nthat is able to take just a handful of photos,", "start": 4.51, "duration": 5.96}, {"text": "and use those to synthesize a moving virtual\ncharacter.", "start": 10.47, "duration": 4.29}, {"text": "Not only that, but it can also synthesize\nthese faces from new viewpoints that the AI", "start": 14.76, "duration": 5.39}, {"text": "hasn\u2019t seen before.", "start": 20.15, "duration": 1.869}, {"text": "These results are truly sublime, however,\nhold on to your papers, because it also works", "start": 22.019, "duration": 5.531}, {"text": "from as little as just one input image.", "start": 27.55, "duration": 4.039}, {"text": "This we refer to as 1-shot learning.", "start": 31.589, "duration": 2.331}, {"text": "You see some examples here, but wait a second\u2026really,\njust one image?", "start": 33.92, "duration": 6.36}, {"text": "If all it needs is really just one photo,\nthis means that we can use famous photographs,", "start": 40.28, "duration": 5.36}, {"text": "and even paintings, and synthesize animations\nfor them.", "start": 45.64, "duration": 4.11}, {"text": "Look at that!", "start": 49.75, "duration": 1.82}, {"text": "Of course, if we show multiple photos to the\nAI, it is able to synthesize better output", "start": 51.57, "duration": 5.629}, {"text": "results, you see such a progression here as\na function of the amount of input data.", "start": 57.199, "duration": 5.461}, {"text": "The painting part I find to be particularly\ncool because it strays away from the kind", "start": 62.66, "duration": 4.97}, {"text": "of data the neural networks were trained on,\nwhich is photos, however, if we have proper", "start": 67.63, "duration": 5.9}, {"text": "intelligence, the AI can learn how different\nparts of the human face move, and generalize", "start": 73.53, "duration": 6.0}, {"text": "this knowledge to paintings as well.", "start": 79.53, "duration": 2.58}, {"text": "The underlying laws are the same, only the\nstyle of the output is different.", "start": 82.11, "duration": 4.94}, {"text": "Absolutely amazing.", "start": 87.05, "duration": 1.73}, {"text": "The paper also showcases an extensive comparison\nsection to previous works, and, as you see", "start": 88.78, "duration": 6.1}, {"text": "here, nothing really compares to this kind\nof quality.", "start": 94.88, "duration": 3.87}, {"text": "I have heard the quote \u201cany sufficiently\nadvanced technology is indistinguishable from", "start": 98.75, "duration": 4.88}, {"text": "magic\u201d so many times in my life, and I was\nlike, OK, well, maybe, but I\u2019m telling you", "start": 103.63, "duration": 7.04}, {"text": "- this is one of those times when I really\nfelt that I am seeing magic at work on my", "start": 110.67, "duration": 5.01}, {"text": "computer screen.", "start": 115.68, "duration": 1.22}, {"text": "So, I know what you\u2019re thinking - how can\nall this wizardry be done?", "start": 116.9, "duration": 5.24}, {"text": "This paper proposes a novel architecture where\n3 neural networks work together.", "start": 122.14, "duration": 5.51}, {"text": "One, the Embedder takes colored images with\nlandmark information and compresses it down", "start": 127.65, "duration": 6.35}, {"text": "into the essence of these images, two, the\nGenerator takes a set of landmarks, a crude", "start": 134.0, "duration": 6.44}, {"text": "approximation of the human face, and synthesizes\na photorealistic result from it.", "start": 140.44, "duration": 5.84}, {"text": "And three, the Discriminator looks at both\nreal and fake images and tries to learn how", "start": 146.28, "duration": 5.94}, {"text": "to tell them apart.", "start": 152.22, "duration": 1.73}, {"text": "As a result, these networks learn together,\nand over time, they improve together, so much", "start": 153.95, "duration": 6.22}, {"text": "so that they can create these amazing animations\nfrom just one source photo.", "start": 160.17, "duration": 5.67}, {"text": "The authors also released a statement on the\npurpose and effects of this technology, which", "start": 165.84, "duration": 5.2}, {"text": "I\u2019ll leave here for a few seconds for our\ninterested viewers.", "start": 171.04, "duration": 3.69}, {"text": "This work was partly done at the Samsung AI\nlab and Skoltech.", "start": 174.73, "duration": 4.58}, {"text": "Congratulations to both institutions.", "start": 179.31, "duration": 2.34}, {"text": "Killer paper.", "start": 181.65, "duration": 1.46}, {"text": "Make sure to check it out in the video description.", "start": 183.11, "duration": 2.65}, {"text": "This episode has been supported by Weights\n& Biases.", "start": 185.76, "duration": 3.54}, {"text": "Weights & Biases provides tools to track your\nexperiments in your deep learning projects.", "start": 189.3, "duration": 4.73}, {"text": "It is like a shared logbook for your team,\nand with this, you can compare your own experiment", "start": 194.03, "duration": 6.13}, {"text": "results, put them next to what your colleagues\ndid and you can discuss your successes and", "start": 200.16, "duration": 4.58}, {"text": "failures much easier.", "start": 204.74, "duration": 2.13}, {"text": "It takes less than 5 minutes to set up and\nis being used by OpenAI, Toyota Research,", "start": 206.87, "duration": 6.21}, {"text": "Stanford and Berkeley.", "start": 213.08, "duration": 1.94}, {"text": "It was also used in this OpenAI project that\nyou see here, which we covered earlier in", "start": 215.02, "duration": 4.579}, {"text": "the series.", "start": 219.599, "duration": 1.0}, {"text": "They reported that experiment tracking was\ncrucial in this project and that this tool", "start": 220.599, "duration": 4.732}, {"text": "saved them quite a bit of time and money.", "start": 225.331, "duration": 3.018}, {"text": "If only I had access to such a tool during\nour last research project where I had to compare", "start": 228.349, "duration": 5.181}, {"text": "the performance of neural networks for months\nand months.", "start": 233.53, "duration": 3.19}, {"text": "Well, it turns out, I will be able to get\naccess to these tools, because, get this,", "start": 236.72, "duration": 5.09}, {"text": "it\u2019s free and will always be free for academics\nand open source projects.", "start": 241.81, "duration": 5.539}, {"text": "Make sure to visit them through wandb.com\nor just click the link in the video description", "start": 247.349, "duration": 7.431}, {"text": "and sign up for a free demo today.", "start": 254.78, "duration": 2.34}, {"text": "Our thanks to Weights & Biases for helping\nus make better videos for you.", "start": 257.12, "duration": 4.31}, {"text": "Thanks for watching and for your generous\nsupport, and I'll see you next time!", "start": 261.43, "duration": 2.4}]