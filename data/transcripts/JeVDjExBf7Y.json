[{"text": "so if you watch my last video you know", "start": 0.06, "duration": 4.29}, {"text": "how a is learned but there's still a big", "start": 2.25, "duration": 4.41}, {"text": "question that he's left unanswered how", "start": 4.35, "duration": 4.8}, {"text": "do my eyes do stuff how do they move or", "start": 6.66, "duration": 5.519}, {"text": "more specifically how do they think that", "start": 9.15, "duration": 5.55}, {"text": "is what this video is all about we're", "start": 12.179, "duration": 4.561}, {"text": "talking about neural networks basically", "start": 14.7, "duration": 4.409}, {"text": "humans attempt to copy the brain to", "start": 16.74, "duration": 5.31}, {"text": "create artificial intelligence now let's", "start": 19.109, "duration": 5.041}, {"text": "start in the obvious place to start the", "start": 22.05, "duration": 4.319}, {"text": "brain more specifically what are neurons", "start": 24.15, "duration": 4.77}, {"text": "because as I'm sure you can imagine we", "start": 26.369, "duration": 4.23}, {"text": "probably have something to do with", "start": 28.92, "duration": 4.139}, {"text": "neural networks our brain is made up of", "start": 30.599, "duration": 5.011}, {"text": "about a hundred billion of these neurons", "start": 33.059, "duration": 4.171}, {"text": "which allow us to think and make", "start": 35.61, "duration": 3.48}, {"text": "decisions and do everything we do in our", "start": 37.23, "duration": 4.2}, {"text": "daily lives and before I get too deep", "start": 39.09, "duration": 4.2}, {"text": "into this I will warn you I'm not a", "start": 41.43, "duration": 4.35}, {"text": "neuroscientist so I might be crudely", "start": 43.29, "duration": 4.38}, {"text": "oversimplifying some things so please", "start": 45.78, "duration": 4.369}, {"text": "forgive me if I do there's a lot of", "start": 47.67, "duration": 4.47}, {"text": "biochemistry happening with potassium", "start": 50.149, "duration": 3.3}, {"text": "and sodium channels and", "start": 52.14, "duration": 2.939}, {"text": "neurotransmitters but let's forget about", "start": 53.449, "duration": 3.581}, {"text": "all that stuff because that's not hugely", "start": 55.079, "duration": 4.291}, {"text": "important for building in your network", "start": 57.03, "duration": 6.18}, {"text": "we just need the overarching idea anyway", "start": 59.37, "duration": 7.319}, {"text": "what is this neuron thing this is Ben he", "start": 63.21, "duration": 5.67}, {"text": "is a neuron he has three main parts the", "start": 66.689, "duration": 3.75}, {"text": "dendrites which connect him to other", "start": 68.88, "duration": 3.39}, {"text": "neurons this is where he receives his", "start": 70.439, "duration": 4.5}, {"text": "input from the other neurons the soma is", "start": 72.27, "duration": 4.41}, {"text": "just the middle bit no one really cares", "start": 74.939, "duration": 3.75}, {"text": "about the soma the other important part", "start": 76.68, "duration": 4.53}, {"text": "is the axon which is like the output of", "start": 78.689, "duration": 5.011}, {"text": "the neuron so Ben's dendrites are", "start": 81.21, "duration": 4.65}, {"text": "connected to other neurons axons and his", "start": 83.7, "duration": 4.169}, {"text": "dendrites receive neurotransmitters from", "start": 85.86, "duration": 4.89}, {"text": "the axons of other neurons which creates", "start": 87.869, "duration": 6.57}, {"text": "a small positive spike in Ben if Ben", "start": 90.75, "duration": 6.78}, {"text": "receives enough positive spikes he just", "start": 94.439, "duration": 5.881}, {"text": "freaks out sending a positive spike down", "start": 97.53, "duration": 4.32}, {"text": "the axon which then releases", "start": 100.32, "duration": 3.75}, {"text": "neurotransmitters to all neurons", "start": 101.85, "duration": 4.769}, {"text": "connected to his axon branches which", "start": 104.07, "duration": 4.77}, {"text": "then produces a positive spike in those", "start": 106.619, "duration": 5.61}, {"text": "neurons and then rinse and repeat so the", "start": 108.84, "duration": 5.43}, {"text": "brain is made up by connecting billions", "start": 112.229, "duration": 4.021}, {"text": "and billions of these neurons it's also", "start": 114.27, "duration": 3.959}, {"text": "important to note that some connections", "start": 116.25, "duration": 3.54}, {"text": "between neurons are stronger than others", "start": 118.229, "duration": 3.03}, {"text": "so if there's a strong connection", "start": 119.79, "duration": 4.259}, {"text": "between neuron a and B but a relatively", "start": 121.259, "duration": 4.831}, {"text": "weak connection between your on a and C", "start": 124.049, "duration": 4.231}, {"text": "when you're an a is triggered then the", "start": 126.09, "duration": 4.199}, {"text": "neuron B receives a much larger positive", "start": 128.28, "duration": 4.35}, {"text": "spike than the neuron C mean", "start": 130.289, "duration": 4.411}, {"text": "neuron B is a lot closer to being", "start": 132.63, "duration": 4.2}, {"text": "triggered than the other new run of", "start": 134.7, "duration": 3.72}, {"text": "course there's a bunch more stuff going", "start": 136.83, "duration": 3.39}, {"text": "on in the brain that I don't understand", "start": 138.42, "duration": 3.36}, {"text": "and even some stuff that no one", "start": 140.22, "duration": 3.33}, {"text": "understands but we have enough", "start": 141.78, "duration": 3.51}, {"text": "information to build our own little", "start": 143.55, "duration": 4.95}, {"text": "brainy thingy and that is what we call a", "start": 145.29, "duration": 5.16}, {"text": "neural network so let's draw a small", "start": 148.5, "duration": 4.86}, {"text": "segment of the connected neurons ah man", "start": 150.45, "duration": 4.26}, {"text": "that's confusing if only there was a", "start": 153.36, "duration": 2.94}, {"text": "much neater way of representing these", "start": 154.71, "duration": 4.05}, {"text": "neurons and connections ah there we go", "start": 156.3, "duration": 4.38}, {"text": "now we're talking so I'm sure you can", "start": 158.76, "duration": 3.27}, {"text": "figure this out but the circles and", "start": 160.68, "duration": 2.97}, {"text": "neurons and the lines are connections", "start": 162.03, "duration": 3.93}, {"text": "between neurons each connection has a", "start": 163.65, "duration": 4.53}, {"text": "strength associated with us this is what", "start": 165.96, "duration": 4.02}, {"text": "we call the wave and it usually ranges", "start": 168.18, "duration": 4.35}, {"text": "between negative 1 and 1 I represent", "start": 169.98, "duration": 4.71}, {"text": "this in my diagrams by thickness and", "start": 172.53, "duration": 3.87}, {"text": "color of the line the thicker the line", "start": 174.69, "duration": 4.11}, {"text": "means the stronger the connection and a", "start": 176.4, "duration": 4.02}, {"text": "red line means a positive connection and", "start": 178.8, "duration": 2.94}, {"text": "a blue line means a negative connection", "start": 180.42, "duration": 4.8}, {"text": "pretty simple stuff ok let's zoom in on", "start": 181.74, "duration": 5.25}, {"text": "a single neuron shall we in a neural", "start": 185.22, "duration": 3.69}, {"text": "network a single neuron is called a", "start": 186.99, "duration": 4.35}, {"text": "perceptron it has many connections to", "start": 188.91, "duration": 3.87}, {"text": "other perceptrons coming in and going", "start": 191.34, "duration": 4.29}, {"text": "out inside the circle bit there are two", "start": 192.78, "duration": 5.01}, {"text": "processes the first is to sum up all the", "start": 195.63, "duration": 3.78}, {"text": "connections coming into the perceptron", "start": 197.79, "duration": 3.9}, {"text": "and the next process is known as the", "start": 199.41, "duration": 3.51}, {"text": "activation function", "start": 201.69, "duration": 2.88}, {"text": "there are many activation functions you", "start": 202.92, "duration": 3.03}, {"text": "can use but for this video we're going", "start": 204.57, "duration": 3.33}, {"text": "to be looking at one of these simplest", "start": 205.95, "duration": 4.02}, {"text": "activation functions the step function", "start": 207.9, "duration": 4.44}, {"text": "the activation function computes how", "start": 209.97, "duration": 4.53}, {"text": "much input the neuron needs before it", "start": 212.34, "duration": 4.23}, {"text": "gets triggered ok this is the function", "start": 214.5, "duration": 3.48}, {"text": "and I know it looks a bit scary I mean", "start": 216.57, "duration": 4.56}, {"text": "it really shouldn't it's not scary all", "start": 217.98, "duration": 4.92}, {"text": "it does is takes the sum of the inputs", "start": 221.13, "duration": 4.17}, {"text": "which we'll call X all it does is return", "start": 222.9, "duration": 5.82}, {"text": "1 if X is positive and returns 0 if X is", "start": 225.3, "duration": 6.72}, {"text": "0 or negative so now the perceptron", "start": 228.72, "duration": 4.77}, {"text": "outputs the result of the activation", "start": 232.02, "duration": 3.78}, {"text": "function to each neuron that it is", "start": 233.49, "duration": 4.08}, {"text": "connected to these outputs are then", "start": 235.8, "duration": 3.36}, {"text": "multiplied by the weights associated", "start": 237.57, "duration": 3.96}, {"text": "with each connection and then rinse and", "start": 239.16, "duration": 5.37}, {"text": "repeat and you got a little brain ok so", "start": 241.53, "duration": 4.56}, {"text": "now hopefully you kind of understand", "start": 244.53, "duration": 2.97}, {"text": "what neural network does and what's", "start": 246.09, "duration": 2.94}, {"text": "going on behind the scenes but I really", "start": 247.5, "duration": 3.48}, {"text": "haven't explained why it works and how", "start": 249.03, "duration": 3.99}, {"text": "this can create behavior so I'm going to", "start": 250.98, "duration": 3.66}, {"text": "explain this with a little example", "start": 253.02, "duration": 4.14}, {"text": "sometimes to know before we start Aleya", "start": 254.64, "duration": 4.56}, {"text": "is a column of new", "start": 257.16, "duration": 4.35}, {"text": "so this is layer 1 also known as the", "start": 259.2, "duration": 4.92}, {"text": "input layer and this is layer 2 3 4 and", "start": 261.51, "duration": 4.98}, {"text": "so on the final layer is also known as", "start": 264.12, "duration": 4.56}, {"text": "the output layer simple right", "start": 266.49, "duration": 4.649}, {"text": "also remember weights are the strength", "start": 268.68, "duration": 4.17}, {"text": "of each connection also I want to", "start": 271.139, "duration": 3.601}, {"text": "introduce the biased neuron this is a", "start": 272.85, "duration": 3.96}, {"text": "neuron like the input neurons but it's", "start": 274.74, "duration": 5.01}, {"text": "always set to 1 this neuron can also be", "start": 276.81, "duration": 4.89}, {"text": "connected to any neuron which isn't in", "start": 279.75, "duration": 3.9}, {"text": "the input layer you will see why we need", "start": 281.7, "duration": 5.219}, {"text": "this later ok let's begin and this", "start": 283.65, "duration": 6.63}, {"text": "example is heavily influenced by brandon", "start": 286.919, "duration": 5.851}, {"text": "Rao's video how deep neural networks", "start": 290.28, "duration": 4.41}, {"text": "work in this video demonstrates how", "start": 292.77, "duration": 3.36}, {"text": "neural networks work with a really good", "start": 294.69, "duration": 3.18}, {"text": "example so I'm gonna borderline", "start": 296.13, "duration": 3.48}, {"text": "plagiarize what he's doing here", "start": 297.87, "duration": 3.96}, {"text": "if you haven't gone seen it what are you", "start": 299.61, "duration": 4.86}, {"text": "doing go go give it a watch but yeah", "start": 301.83, "duration": 5.339}, {"text": "let's get get into it ok now let's", "start": 304.47, "duration": 4.47}, {"text": "introduce our example we're going to be", "start": 307.169, "duration": 3.841}, {"text": "doing some computer vision but let's", "start": 308.94, "duration": 4.14}, {"text": "keep it ridiculously simple our camera", "start": 311.01, "duration": 4.62}, {"text": "sees a 2 by 2 image and pixels can only", "start": 313.08, "duration": 5.04}, {"text": "be black or what we want it to be able", "start": 315.63, "duration": 4.349}, {"text": "to recognize checkerboard pattern so", "start": 318.12, "duration": 3.81}, {"text": "there are 2 possibilities that we want", "start": 319.979, "duration": 4.651}, {"text": "either this or this and this is our", "start": 321.93, "duration": 4.35}, {"text": "neural network which can recognize these", "start": 324.63, "duration": 3.39}, {"text": "patterns it's scary I know but to help", "start": 326.28, "duration": 3.96}, {"text": "you understand what's going on let's", "start": 328.02, "duration": 4.74}, {"text": "show what each neuron represents a good", "start": 330.24, "duration": 4.11}, {"text": "way to think about a neural network is", "start": 332.76, "duration": 3.48}, {"text": "that each layer is combining features", "start": 334.35, "duration": 4.17}, {"text": "from the previous layer what I remember", "start": 336.24, "duration": 3.66}, {"text": "this well first let's look at the input", "start": 338.52, "duration": 3.78}, {"text": "layer we have for neurons corresponding", "start": 339.9, "duration": 4.829}, {"text": "to the 4 pixels from our camera you can", "start": 342.3, "duration": 4.11}, {"text": "see that the bottom neuron in the second", "start": 344.729, "duration": 3.301}, {"text": "layer is combining the features of the", "start": 346.41, "duration": 3.87}, {"text": "top right and bottom left pixels", "start": 348.03, "duration": 4.23}, {"text": "resulting in a diagonal line that", "start": 350.28, "duration": 4.17}, {"text": "combined with the white diagonal line in", "start": 352.26, "duration": 4.14}, {"text": "the opposite direction creates a", "start": 354.45, "duration": 3.39}, {"text": "checkerboard pattern that we are looking", "start": 356.4, "duration": 3.78}, {"text": "for alright let's go over this neuron by", "start": 357.84, "duration": 3.84}, {"text": "neuron and run through the math which is", "start": 360.18, "duration": 3.6}, {"text": "working behind the scenes in our neural", "start": 361.68, "duration": 4.53}, {"text": "network black pixels are ones and white", "start": 363.78, "duration": 4.62}, {"text": "pixels are minus ones so we set our", "start": 366.21, "duration": 4.56}, {"text": "input layout from the pixels so the top", "start": 368.4, "duration": 4.65}, {"text": "left is black and therefore it's a 1 and", "start": 370.77, "duration": 3.84}, {"text": "the bottom right is also black so that", "start": 373.05, "duration": 4.32}, {"text": "one's a 1 and then the other 2 pixels", "start": 374.61, "duration": 4.92}, {"text": "are white to this set as minus 1 let's", "start": 377.37, "duration": 3.51}, {"text": "look at the top neuron in the second", "start": 379.53, "duration": 3.15}, {"text": "layer and let's do the math the blue", "start": 380.88, "duration": 3.42}, {"text": "lines are connections with whites of", "start": 382.68, "duration": 3.0}, {"text": "minus 1 and the red lines are", "start": 384.3, "duration": 4.69}, {"text": "connections with whites of 1", "start": 385.68, "duration": 5.26}, {"text": "all right so we've got our input here", "start": 388.99, "duration": 5.54}, {"text": "and we've got our input neurons set up", "start": 390.94, "duration": 6.24}, {"text": "so let's run through the math we got one", "start": 394.53, "duration": 5.38}, {"text": "x blue line so weight of minus 1 1 times", "start": 397.18, "duration": 3.9}, {"text": "minus 1 is minus 1", "start": 399.91, "duration": 2.46}, {"text": "it couldn't be some very difficult math", "start": 401.08, "duration": 3.3}, {"text": "in here so watch out 1 times minus 1", "start": 402.37, "duration": 5.549}, {"text": "again is minus 1 bias notice is always", "start": 404.38, "duration": 7.11}, {"text": "outputting a 1 times y minus 1 equals", "start": 407.919, "duration": 6.361}, {"text": "minus 1 so we'll add this up that equals", "start": 411.49, "duration": 5.34}, {"text": "minus 3 which is less than or equal to 0", "start": 414.28, "duration": 6.75}, {"text": "so this outputs a 0 next one we got 1", "start": 416.83, "duration": 5.04}, {"text": "times 1 is 1", "start": 421.03, "duration": 2.34}, {"text": "and I'm just gonna run through this you", "start": 421.87, "duration": 6.24}, {"text": "get it plus then the bias is minus 1 so", "start": 423.37, "duration": 7.47}, {"text": "this is a sum total of 1 which is", "start": 428.11, "duration": 4.02}, {"text": "greater than or equal to 0 so this", "start": 430.84, "duration": 2.79}, {"text": "outputs a 1 which makes sense because", "start": 432.13, "duration": 4.71}, {"text": "this feature is found each each neuron", "start": 433.63, "duration": 5.159}, {"text": "is looking for a feature and this is a", "start": 436.84, "duration": 3.48}, {"text": "diagonal line from top left to bottom", "start": 438.789, "duration": 3.541}, {"text": "right and you can see we have that here", "start": 440.32, "duration": 3.96}, {"text": "whereas this one here was a white", "start": 442.33, "duration": 3.42}, {"text": "diagonal line from top left to bottom", "start": 444.28, "duration": 4.259}, {"text": "right which wasn't found because there", "start": 445.75, "duration": 4.02}, {"text": "isn't any in the input which is why it", "start": 448.539, "duration": 3.151}, {"text": "output is 0 all right those working so", "start": 449.77, "duration": 4.05}, {"text": "far so now let's run through some more", "start": 451.69, "duration": 5.19}, {"text": "math minus 1 times minus 1 is 1 plus", "start": 453.82, "duration": 6.42}, {"text": "minus 1 times minus 1 is 1 minus 1 and", "start": 456.88, "duration": 6.659}, {"text": "once again that equals 1 yeah puts one", "start": 460.24, "duration": 5.31}, {"text": "name exist feature was found which again", "start": 463.539, "duration": 4.651}, {"text": "it's an e but it makes sense and then", "start": 465.55, "duration": 4.859}, {"text": "quickly run through it minus 1 plus", "start": 468.19, "duration": 7.38}, {"text": "minus 1 plus minus 1 equals minus 3 you", "start": 470.409, "duration": 6.81}, {"text": "shot puts a zero this feature was", "start": 475.57, "duration": 4.589}, {"text": "nothing okay second layer done pretty", "start": 477.219, "duration": 6.301}, {"text": "simple so far now let's have a look at", "start": 480.159, "duration": 4.741}, {"text": "the third layer let's look at this new", "start": 483.52, "duration": 6.769}, {"text": "one first so we got 1 & 1 so 1 times 1", "start": 484.9, "duration": 5.389}, {"text": "I'm just gonna run through it you get it", "start": 490.38, "duration": 4.44}, {"text": "so this bit was the bias Neron and then", "start": 494.88, "duration": 10.839}, {"text": "this one we got 0 plus 0 minus 1 equals", "start": 497.62, "duration": 10.53}, {"text": "minus 1 which means this neuron was", "start": 505.719, "duration": 3.811}, {"text": "activated in this one wasn't which means", "start": 508.15, "duration": 3.18}, {"text": "we found this checkerboard pattern which", "start": 509.53, "duration": 4.11}, {"text": "if you look closely is the same as our", "start": 511.33, "duration": 5.519}, {"text": "input and then this final neuron just", "start": 513.64, "duration": 5.85}, {"text": "combines these two so we got 1 times 1", "start": 516.849, "duration": 5.261}, {"text": "is 1 plus 0 times 1 is 0", "start": 519.49, "duration": 4.45}, {"text": "and the vice-mayor is not connected to", "start": 522.11, "duration": 4.71}, {"text": "this so this equals one which means the", "start": 523.94, "duration": 4.68}, {"text": "up final output is one which means we", "start": 526.82, "duration": 3.99}, {"text": "found our checkerboard pattern which is", "start": 528.62, "duration": 4.05}, {"text": "of course what we're looking for so it", "start": 530.81, "duration": 5.07}, {"text": "works beautiful now let's talk about the", "start": 532.67, "duration": 4.71}, {"text": "need for the bias neuron because it", "start": 535.88, "duration": 3.27}, {"text": "really didn't have much of an effect on", "start": 537.38, "duration": 3.51}, {"text": "the previous example so let's look at a", "start": 539.15, "duration": 4.02}, {"text": "new example this one obviously shouldn't", "start": 540.89, "duration": 4.02}, {"text": "output a one because it's simply not a", "start": 543.17, "duration": 3.57}, {"text": "checkerboard pattern so first we need to", "start": 544.91, "duration": 3.27}, {"text": "set the input to represent this new", "start": 546.74, "duration": 3.78}, {"text": "image ok I'll skip over layer two", "start": 548.18, "duration": 4.35}, {"text": "because that works as it should but", "start": 550.52, "duration": 3.6}, {"text": "what's interesting is in the third layer", "start": 552.53, "duration": 3.81}, {"text": "let's look at the bottom neuron now", "start": 554.12, "duration": 3.84}, {"text": "let's remove the bias neuron and see", "start": 556.34, "duration": 3.63}, {"text": "what happens just quickly do the map 0", "start": 557.96, "duration": 4.86}, {"text": "times 1 is 0 plus 1 times 1 is 1 so the", "start": 559.97, "duration": 4.62}, {"text": "total input is 1 which means that this", "start": 562.82, "duration": 3.87}, {"text": "neuron is triggered but hang on the", "start": 564.59, "duration": 3.57}, {"text": "feature which this neuron was looking", "start": 566.69, "duration": 3.3}, {"text": "for was a checkerboard pattern so it", "start": 568.16, "duration": 3.42}, {"text": "shouldn't be triggered so what happened", "start": 569.99, "duration": 2.91}, {"text": "if we look at the neurons in the", "start": 571.58, "duration": 3.06}, {"text": "previous layer which this neuron is", "start": 572.9, "duration": 3.78}, {"text": "connected to one of them is activated", "start": 574.64, "duration": 3.66}, {"text": "but the other one isn't but we want both", "start": 576.68, "duration": 3.99}, {"text": "of them to be activated so we want the", "start": 578.3, "duration": 4.08}, {"text": "neuron in the 3rd layer to be only", "start": 580.67, "duration": 3.78}, {"text": "activated when the total is more than 1", "start": 582.38, "duration": 4.05}, {"text": "instead of the current situation which", "start": 584.45, "duration": 4.74}, {"text": "activates on an input greater than zero", "start": 586.43, "duration": 4.35}, {"text": "so how can we do this well we could", "start": 589.19, "duration": 3.66}, {"text": "always subtract one from the total that", "start": 590.78, "duration": 3.51}, {"text": "way the total would need to be greater", "start": 592.85, "duration": 3.12}, {"text": "than one before we subtract the one", "start": 594.29, "duration": 3.66}, {"text": "which is what we want okay now this is", "start": 595.97, "duration": 3.51}, {"text": "where the biased neuron comes in", "start": 597.95, "duration": 2.94}, {"text": "remember the biased neuron is always", "start": 599.48, "duration": 3.15}, {"text": "outputting a 1 this multiplied by a", "start": 600.89, "duration": 4.59}, {"text": "weight of minus 1 gets minus 1 and voila", "start": 602.63, "duration": 5.52}, {"text": "we are always subtracting 1 from that", "start": 605.48, "duration": 4.29}, {"text": "neuron now let's go over the example", "start": 608.15, "duration": 5.01}, {"text": "again the sum is now 0 times 1 is 0 plus", "start": 609.77, "duration": 6.24}, {"text": "1 times 1 brings us to 1 now considering", "start": 613.16, "duration": 6.0}, {"text": "the biased neuron we add 1 times minus 1", "start": 616.01, "duration": 5.4}, {"text": "so now the total is reduced to 0 which", "start": 619.16, "duration": 4.16}, {"text": "means that neuron isn't triggered and", "start": 621.41, "duration": 6.09}, {"text": "voila nailed it as an exercise for", "start": 623.32, "duration": 6.37}, {"text": "anyone watching try other inputs and see", "start": 627.5, "duration": 4.47}, {"text": "how the neurons activate and test it out", "start": 629.69, "duration": 4.05}, {"text": "an input which isn't a checkerboard", "start": 631.97, "duration": 3.03}, {"text": "pattern should have neither of the", "start": 633.74, "duration": 2.94}, {"text": "output neurons output a 1", "start": 635.0, "duration": 3.87}, {"text": "of course neural networks get a lot more", "start": 636.68, "duration": 3.96}, {"text": "complicated than this so it's usually", "start": 638.87, "duration": 4.2}, {"text": "not an option to manually set all the", "start": 640.64, "duration": 4.35}, {"text": "neurons and weights this is where the", "start": 643.07, "duration": 4.17}, {"text": "genetic algorithm comes in to evolve and", "start": 644.99, "duration": 3.81}, {"text": "learn the weights which create the", "start": 647.24, "duration": 3.48}, {"text": "desirable behavior those with better", "start": 648.8, "duration": 3.75}, {"text": "behavior will survive and pass on its", "start": 650.72, "duration": 3.27}, {"text": "genes which in this case is the weights", "start": 652.55, "duration": 3.42}, {"text": "and slowly through the magic", "start": 653.99, "duration": 4.079}, {"text": "evolution the neural network learns how", "start": 655.97, "duration": 3.929}, {"text": "to do the desired tasks such as jumping", "start": 658.069, "duration": 4.02}, {"text": "over cacti or finding food or shooting", "start": 659.899, "duration": 4.17}, {"text": "asteroids and it will probably make a", "start": 662.089, "duration": 3.78}, {"text": "video on how to combine your networks", "start": 664.069, "duration": 3.901}, {"text": "and the genetic algorithm sometime in", "start": 665.869, "duration": 3.72}, {"text": "the future so stay tuned for that", "start": 667.97, "duration": 3.899}, {"text": "so hopefully you learn something from", "start": 669.589, "duration": 3.78}, {"text": "watching this and if you did you know", "start": 671.869, "duration": 3.36}, {"text": "want to be even better retaining that", "start": 673.369, "duration": 3.36}, {"text": "knowledge it is very common for people", "start": 675.229, "duration": 3.81}, {"text": "to watch educational videos like this", "start": 676.729, "duration": 4.56}, {"text": "and then for them to just click away and", "start": 679.039, "duration": 3.66}, {"text": "forget about everything they just", "start": 681.289, "duration": 3.57}, {"text": "learned once again burned dog comes in", "start": 682.699, "duration": 3.84}, {"text": "to save the day they have an entire", "start": 684.859, "duration": 3.15}, {"text": "course on neural networks with", "start": 686.539, "duration": 3.66}, {"text": "interactive lessons on everything from", "start": 688.009, "duration": 4.2}, {"text": "the brain to very complicated neural", "start": 690.199, "duration": 3.51}, {"text": "networks such as convolutional neural", "start": 692.209, "duration": 3.69}, {"text": "networks which are just insane they", "start": 693.709, "duration": 3.78}, {"text": "break down each topic into small chunks", "start": 695.899, "duration": 3.87}, {"text": "which makes very difficult topics such", "start": 697.489, "duration": 4.981}, {"text": "as neural networks super easy the first", "start": 699.769, "duration": 4.92}, {"text": "200 people to use this link will get 20%", "start": 702.47, "duration": 4.439}, {"text": "off an annual subscription so if you", "start": 704.689, "duration": 3.84}, {"text": "want to deepen your understanding of the", "start": 706.909, "duration": 3.72}, {"text": "topic of neural networks and support", "start": 708.529, "duration": 3.72}, {"text": "this channel at the same time then", "start": 710.629, "duration": 4.931}, {"text": "checking them out would be a great idea", "start": 712.249, "duration": 22.511}, {"text": "[Music]", "start": 715.56, "duration": 19.2}]